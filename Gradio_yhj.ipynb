{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv5ë¥¼ ì‚¬ìš©í•œ Detection ìˆ˜í–‰ ë° Detection ê²°ê³¼ ì €ì¥\n",
        "- Input: ì›¹ìº ì˜ ìŠ¤ëƒ…ìƒ· or ì—…ë¡œë“œ ì´ë¯¸ì§€\n",
        "- Output: Detection ëœ Objectì˜ bboxê°€ ê·¸ë ¤ì§„ Image + Bbox ì •ë³´ Json\n",
        "    - ì²´í¬ë°•ìŠ¤ë¥¼ ë§Œë“¤ì–´ Save dirì— Imageì™€ Jsonì„ ì €ì¥í•  ìˆ˜ ìˆë„ë¡ í•¨.\n",
        "- ê·¸ ì™¸ ê¸°ëŠ¥: ì£¼ì–´ì§„ ID ë° ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì„œ ë¡œê·¸ì¸ì„ í•´ì•¼ Detectorë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•¨.\n",
        "    - ID: haejun\n",
        "    - PWD: yang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading YOLOv5 model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ğŸš€ 2025-10-15 Python-3.10.13 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded on cuda\n",
            "* Running on local URL:  http://127.0.0.1:8002\n",
            "* Running on public URL: https://86d1f639dc30d82946.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://86d1f639dc30d82946.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch, cv2, numpy as np, time, json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# ============== YOLOv5 ë¡œë“œ ==============\n",
        "print(\"Loading YOLOv5 model...\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", trust_repo=True).to(device).eval()\n",
        "if device == \"cuda\":\n",
        "    model.half()  # ë¬¸ì œ ìˆìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬\n",
        "names = getattr(model, \"names\", {})\n",
        "print(f\"Model loaded on {device}\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def detection(frame: np.ndarray, conf_threshold: float = 0.3):\n",
        "    \"\"\"RGB np.uint8 Image 1ì¥ â†’ (annotated RGB, status, raw_det_list)\"\"\"\n",
        "    if frame is None:\n",
        "        return None, \"Status: please capture or upload an image.\", []\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Detectionì€ BGR ì´ë¯¸ì§€ë¡œ ì§„í–‰\n",
        "    bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "    bgr = np.ascontiguousarray(bgr)\n",
        "\n",
        "    results = model(bgr, size=640)\n",
        "    det = results.xyxy[0].detach().float().cpu().numpy() if hasattr(results, \"xyxy\") else np.empty((0, 6))\n",
        "\n",
        "    out = frame.copy()  # ì¶œë ¥ì€ RGB ìœ ì§€\n",
        "    people = 0\n",
        "    kept = []  # JSON ì €ì¥ìš©\n",
        "\n",
        "    H, W = out.shape[:2]\n",
        "    for *xyxy, conf, cls in det:\n",
        "        conf = float(conf)\n",
        "        cls  = int(cls)\n",
        "        if conf < conf_threshold:\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, xyxy)\n",
        "        w, h = max(0, x2 - x1), max(0, y2 - y1)\n",
        "        cx, cy = x1 + w/2.0, y1 + h/2.0\n",
        "\n",
        "        if cls == 0:  # person ì¹´ìš´íŠ¸\n",
        "            people += 1\n",
        "\n",
        "        kept.append({\n",
        "            \"class_id\": cls,\n",
        "            \"class_name\": names.get(cls, str(cls)),\n",
        "            \"confidence\": conf,\n",
        "            \"bbox_xyxy\": [x1, y1, x2, y2],\n",
        "            # \"bbox_width\":  w,\n",
        "            # \"bbox_height\": h,\n",
        "            # \"bbox_area\":   w * h,\n",
        "            \"center\": [cx, cy]\n",
        "        })\n",
        "\n",
        "        # ì‹œê°í™”\n",
        "        label = f\"{names.get(cls, str(cls))} {conf:.2f}\"\n",
        "        cv2.rectangle(out, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "        (tw, th), bl = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "        y1t = max(0, y1 - th - bl - 3)\n",
        "        cv2.rectangle(out, (x1, y1t), (x1+tw+6, y1t+th+bl+6), (0,120,0), -1)\n",
        "        cv2.putText(out, label, (x1+3, y1t+th+3), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                    (255,255,255), 1, cv2.LINE_AA)\n",
        "\n",
        "    fps = 1.0 / max(1e-6, time.time() - t0)\n",
        "    status = f\"Status: Detected {people} people | FPS: {fps:.1f}\"\n",
        "    return out, status, kept\n",
        "\n",
        "def detect_from_inputs(webcam_frame, uploaded_frame, conf, save_img, save_json, save_dir):\n",
        "    \"\"\"ì›¹ìº  ìš°ì„ , ì—†ìœ¼ë©´ ì—…ë¡œë“œ Image ì‚¬ìš©. ì €ì¥ ì˜µì…˜ì— ë”°ë¼ íŒŒì¼ ì €ì¥.\"\"\"\n",
        "    frame = webcam_frame if webcam_frame is not None else uploaded_frame\n",
        "    out, status, kept = detection(frame, conf)\n",
        "\n",
        "    # ì €ì¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„\n",
        "    if (save_img or save_json) and out is not None:\n",
        "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "        stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # íŒŒì¼ ë² ì´ìŠ¤ëª…\n",
        "        base_jpg = f\"{stamp}_det.jpg\"\n",
        "        base_json = f\"{stamp}_det.json\"\n",
        "\n",
        "        if save_img:\n",
        "            cv2.imwrite(str(Path(save_dir)/base_jpg), cv2.cvtColor(out, cv2.COLOR_RGB2BGR))\n",
        "            status += f\" | Saved image: {base_jpg}\"\n",
        "\n",
        "        if save_json:\n",
        "            H, W = out.shape[:2]\n",
        "            payload = {\n",
        "                \"source\": base_jpg if save_img else None,\n",
        "                \"timestamp\": datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
        "                \"image_size\": [int(H), int(W)],\n",
        "                \"detections\": kept\n",
        "            }\n",
        "            with open(Path(save_dir)/base_json, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(payload, f, ensure_ascii=False, indent=2)\n",
        "            status += f\" | Saved JSON: {base_json}\"\n",
        "\n",
        "    return out, status\n",
        "\n",
        "# ============== Gradio UI ==============\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## YOLOv5 Detector + JSON Export\\n\"\n",
        "                \"- ì›¹ìº  ìŠ¤ëƒ…ìƒ·(ì¹´ë©”ë¼ ì•„ì´ì½˜) ë˜ëŠ” Image ì—…ë¡œë“œ í›„ Run Detection.\\n\"\n",
        "                \"- ì²´í¬ë°•ìŠ¤ë¡œ Image/JSON ì €ì¥ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        webcam_snap = gr.Image(label=\"Webcam Snapshot\", sources=[\"webcam\"], type=\"numpy\")\n",
        "        upload_img  = gr.Image(label=\"Or Upload an Image\", type=\"numpy\")\n",
        "        result_img  = gr.Image(label=\"Detection Result\", type=\"numpy\")\n",
        "\n",
        "    status_box = gr.Textbox(label=\"Processing Status\", interactive=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        conf      = gr.Slider(0.0, 1.0, value=0.3, step=0.05, label=\"Confidence Threshold\")\n",
        "        save_img  = gr.Checkbox(value=True,  label=\"Save annotated image\")\n",
        "        save_js   = gr.Checkbox(value=True,  label=\"Save bbox JSON\")\n",
        "        save_dir  = gr.Textbox(value=\"/workspace/out_snapshots\", label=\"Save dir\", scale=2)\n",
        "\n",
        "    run_btn = gr.Button(\"Run Detection\", variant=\"primary\")\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=detect_from_inputs,\n",
        "        inputs=[webcam_snap, upload_img, conf, save_img, save_js, save_dir],\n",
        "        outputs=[result_img, status_box]\n",
        "    )\n",
        "\n",
        "demo.queue().launch(server_port=8002, share=True, auth=(\"haejun\", \"yang\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
